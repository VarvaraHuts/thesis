{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from iwnlp.iwnlp_wrapper import IWNLPWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = IWNLPWrapper(lemmatizer_path='C:/Users/1/Desktop/thesis/IWNLP.Lemmatizer_20170501.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lemma(word):\n",
    "    lemma = lemmatizer.lemmatize_plain(word)\n",
    "    if lemma is None:\n",
    "        return capitalize(word)\n",
    "    else:\n",
    "        return capitalize(lemma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def capitalize(word):\n",
    "    if len(word) > 1:\n",
    "        word = word[0].upper() + word[1:]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_words = open('C:/Users/1/Desktop/thesis/wortliste.txt', 'r', encoding='utf-8')\n",
    "lines_words = file_words.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = []\n",
    "for line in lines_words:\n",
    "    line_new = line.split(' ')\n",
    "    dictionary.append(capitalize(line_new[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_in_dic(word):\n",
    "    if word in dictionary:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_part(word):\n",
    "    if len(word) > 1 and is_in_dic(word) is True:\n",
    "        return True\n",
    "    if (word.endswith('n') or word.endswith('e') or word.endswith('s')) and is_in_dic(word[:-1]):\n",
    "        return True\n",
    "    if (word.endswith('en') or word.endswith('er') or word.endswith('es')) and is_in_dic(word[:-2]):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_compound(word):\n",
    "    max_ind = len(word)\n",
    "    \n",
    "    for ind, char in enumerate(word):\n",
    "        left_compound = word[0:max_ind-ind]\n",
    "        right_compound = word[max_ind-ind:max_ind]\n",
    "        \n",
    "        if is_part(left_compound) and len(left_compound) != len(word):\n",
    "            right_compound_upper = capitalize(right_compound)\n",
    "            if is_part(right_compound_upper):\n",
    "                if not is_in_dic(left_compound) and is_in_dic(left_compound[:-1]):\n",
    "                    return (left_compound[:-1], right_compound_upper)\n",
    "                if not is_in_dic(left_compound) and is_in_dic(left_compound[:-2]):\n",
    "                    return (left_compound[:-2], right_compound_upper)\n",
    "                if is_in_dic(left_compound):\n",
    "                    return (left_compound, right_compound_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_compound_of_three(word):\n",
    "    max_ind = len(word)\n",
    "    \n",
    "    for ind1 in range(max_ind):\n",
    "        for ind2 in range(ind1, max_ind):\n",
    "            left_part = word[:ind1]\n",
    "            middle_part = word[ind1:ind2]\n",
    "            right_part = word[ind2:]\n",
    "            \n",
    "            if is_part(left_part):\n",
    "                middle_part_upper = capitalize(middle_part)\n",
    "                right_part_upper = capitalize(right_part)\n",
    "                if is_part(middle_part_upper) and is_part(right_part_upper):\n",
    "                    if not is_in_dic(left_part) and is_in_dic(left_part[:-1]) and is_in_dic(middle_part_upper):\n",
    "                        return (left_part[:-1], middle_part_upper, right_part_upper)\n",
    "                    if not is_in_dic(left_part) and is_in_dic(left_part[:-2]) and is_in_dic(middle_part_upper):\n",
    "                        return (left_part[:-2], middle_part_upper, right_part_upper)  \n",
    "                    if is_in_dic(left_part) and not is_in_dic(middle_part_upper) and is_in_dic(middle_part_upper[:-1]):\n",
    "                        return (left_part, middle_part_upper[:-1], right_part_upper)\n",
    "                    if is_in_dic(left_part) and not is_in_dic(middle_part_upper) and is_in_dic(middle_part_upper[:-2]):\n",
    "                        return (left_part, middle_part_upper[:-2], right_part_upper)\n",
    "                    if is_in_dic(left_part) and is_in_dic(middle_part_upper):\n",
    "                        return (left_part, middle_part_upper, right_part_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = open(\"C:/Users/1/Desktop/thesis/corpus_final/corpus_de.txt\", \"r\", encoding=\"utf-8\")\n",
    "f = open(\"C:/Users/1/Desktop/thesis/corpus_final/corpus_de_splitted.txt\", \"w\", encoding=\"utf-8\")\n",
    "w = open(\"C:/Users/1/Desktop/thesis/corpus_final/compounds_extracted.txt\", \"w\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = s.readlines()\n",
    "lines_new = []\n",
    "\n",
    "for index in range(len(lines)):\n",
    "    line = lines[index].strip(\"\\n\")\n",
    "    tokens = line.split(\" \")\n",
    "    tokens_new = []\n",
    "    for token in tokens:\n",
    "        token_cap = capitalize(token)\n",
    "        \n",
    "        if split_compound(token_cap):\n",
    "            comp = split_compound(token_cap)\n",
    "            tokens_new.append(comp[0])\n",
    "            tokens_new.append(comp[1])\n",
    "            w.write(comp[0] + \"/\" + comp[1] + \"/\" + token + \"/\" + str(index) + \"\\n\")\n",
    "            \n",
    "        if split_compound_of_three(token_cap):\n",
    "            comp2 = split_compound_of_three(token_cap)\n",
    "            tokens_new.append(comp2[0])\n",
    "            tokens_new.append(comp2[1])\n",
    "            tokens_new.append(comp2[2])\n",
    "            w.write(comp2[0] + \"/\" + comp2[1] + \"/\" + comp2[2] + \"/\" + token + \"/\" + str(index) + \"\\n\")\n",
    "            \n",
    "        if not split_compound(token) and not split_compound_of_three(token):\n",
    "            tokens_new.append(token)\n",
    "            \n",
    "    line_new = \" \".join(tokens_new)\n",
    "    lines_new.append(line_new)\n",
    "w.close()\n",
    "\n",
    "for line in lines_new:\n",
    "    f.write(line+\"\\n\")\n",
    "f.close()\n",
    "\n",
    "s.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
