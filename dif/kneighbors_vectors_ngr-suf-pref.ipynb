{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format(\"D:/wiki.de.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decapitalize(word):\n",
    "    if len(word) > 1:\n",
    "        word = word[0].lower() + word[1:]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no suffixes\n",
    "def all_dist(vector_1,vector_2):\n",
    "    cur_dist = 0\n",
    "    for i in range((len(vector_1))):\n",
    "        if i == 0 or i == 2:\n",
    "            try:\n",
    "                ith_dist = glove_model.similarity(decapitalize(vector_1[i]), decapitalize(vector_2[i]))\n",
    "                cur_dist = (1-ith_dist)*(1-ith_dist)\n",
    "            except:\n",
    "                ith_dist = 0\n",
    "                cur_dist = (1-ith_dist)*(1-ith_dist)\n",
    "        else:\n",
    "            if vector_1[i] != vector_2[i]:\n",
    "                cur_dist += 1\n",
    "    return cur_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"C:/Users/1/Desktop/compounds_final.txt\", \"r\", encoding=\"utf-8\")\n",
    "lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no suffixes\n",
    "matrix = []\n",
    "for line in lines:\n",
    "    vectors = []\n",
    "    types = []\n",
    "    line = line.strip(\"\\n\")\n",
    "    items = line.split(\"/\")\n",
    "    p1 = [items[1][:1]] + [items[1][:2]] + [items[1][:3]]\n",
    "    p2 = [items[4][:1]] + [items[4][:2]] + [items[4][:3]]\n",
    "    s1 = [items[1][-1]] + [items[1][-2:]] + [items[1][-3:]]\n",
    "    s2 = [items[4][-1]] + [items[4][-2:]] + [items[4][-3:]]\n",
    "    items_new = items[1:3] + p1 + s1 + items[4:6] + p2 + s2 + [items[7]]\n",
    "    for item in items_new:\n",
    "        vectors.append(item)\n",
    "    types.append(items[-1])\n",
    "    tp = (vectors,types)\n",
    "    matrix.append(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Engel', '<NN>', 'E', 'En', 'Eng', 'l', 'el', 'gel', 'Bild', '<+NN>', 'B', 'Bi', 'Bil', 'd', 'ld', 'ild', 's'], ['N'])\n",
      "(['Wolke', '<NN>', 'W', 'Wo', 'Wol', 'e', 'ke', 'lke', 'Schatten', '<+NN>', 'S', 'Sc', 'Sch', 'n', 'en', 'ten', 'n'], ['NN'])\n"
     ]
    }
   ],
   "source": [
    "for item in matrix[:2]:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixX = []\n",
    "matrixY = []\n",
    "for item in matrix:\n",
    "    matrixX.append(item[0])\n",
    "    matrixY.append(item[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(matrixX)\n",
    "y = np.array(matrixY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         AN       0.45      0.62      0.52      1349\n",
      "          N       0.43      0.29      0.34      1250\n",
      "         NN       0.22      0.19      0.20       540\n",
      "\n",
      "avg / total       0.40      0.41      0.40      3139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_predicts = []\n",
    "tests = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    predictions = []\n",
    "    for vector in X_test:\n",
    "        distances = []\n",
    "        types = []\n",
    "        for x in range(len(X_train)):\n",
    "            distance = all_dist(X_train[x], vector)\n",
    "            d_t = (distance, y_train[x])\n",
    "            distances.append(d_t)\n",
    "            types.append(y_train[x])\n",
    "        distances_sort = sorted(distances)\n",
    "        types_sort = []\n",
    "        for item in distances_sort[:3]:\n",
    "            types_sort.append(item[1])\n",
    "        maxx = max(set(types_sort), key=types_sort.count)\n",
    "        predictions.append(maxx)\n",
    "    y_test = y_test.tolist()\n",
    "    all_predicts.extend(predictions)\n",
    "    tests.extend(y_test)\n",
    "    \n",
    "print(classification_report(tests, all_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with suffixes\n",
    "def all_dist(vector_1,vector_2):\n",
    "    cur_dist = 0\n",
    "    for i in range((len(vector_1))):\n",
    "        if i == 0 or i == 3:\n",
    "            try:\n",
    "                ith_dist = glove_model.similarity(decapitalize(vector_1[i]), decapitalize(vector_2[i]))\n",
    "                cur_dist = (1-ith_dist)*(1-ith_dist)\n",
    "            except:\n",
    "                ith_dist = 0\n",
    "                cur_dist = (1-ith_dist)*(1-ith_dist)\n",
    "        else:\n",
    "            if vector_1[i] != vector_2[i]:\n",
    "                cur_dist += 1\n",
    "    return cur_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with suffixes\n",
    "matrix = []\n",
    "for line in lines:\n",
    "    vectors = []\n",
    "    types = []\n",
    "    line = line.strip(\"\\n\")\n",
    "    items = line.split(\"/\")\n",
    "    p1 = [items[1][:1]] + [items[1][:2]] + [items[1][:3]]\n",
    "    p2 = [items[4][:1]] + [items[4][:2]] + [items[4][:3]]\n",
    "    s1 = [items[1][-1]] + [items[1][-2:]] + [items[1][-3:]]\n",
    "    s2 = [items[4][-1]] + [items[4][-2:]] + [items[4][-3:]]\n",
    "    items_new = items[1:4] + p1 + s1 + items[4:7] + p2 + s2 + [items[7]]\n",
    "    for item in items_new:\n",
    "        vectors.append(item)\n",
    "    types.append(items[-1])\n",
    "    tp = (vectors,types)\n",
    "    matrix.append(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Engel', '<NN>', 'no', 'E', 'En', 'Eng', 'l', 'el', 'gel', 'Bild', '<+NN>', 'no', 'B', 'Bi', 'Bil', 'd', 'ld', 'ild', 's'], ['N'])\n",
      "(['Wolke', '<NN>', 'no', 'W', 'Wo', 'Wol', 'e', 'ke', 'lke', 'Schatten', '<+NN>', 'no', 'S', 'Sc', 'Sch', 'n', 'en', 'ten', 'n'], ['NN'])\n"
     ]
    }
   ],
   "source": [
    "for item in matrix[:2]:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixX = []\n",
    "matrixY = []\n",
    "for item in matrix:\n",
    "    matrixX.append(item[0])\n",
    "    matrixY.append(item[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(matrixX)\n",
    "y = np.array(matrixY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         AN       0.44      0.62      0.52      1349\n",
      "          N       0.39      0.24      0.30      1250\n",
      "         NN       0.23      0.20      0.21       540\n",
      "\n",
      "avg / total       0.39      0.40      0.38      3139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_predicts = []\n",
    "tests = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    predictions = []\n",
    "    for vector in X_test:\n",
    "        distances = []\n",
    "        types = []\n",
    "        for x in range(len(X_train)):\n",
    "            distance = all_dist(X_train[x], vector)\n",
    "            d_t = (distance, y_train[x])\n",
    "            distances.append(d_t)\n",
    "            types.append(y_train[x])\n",
    "        distances_sort = sorted(distances)\n",
    "        types_sort = []\n",
    "        for item in distances_sort[:3]:\n",
    "            types_sort.append(item[1])\n",
    "        maxx = max(set(types_sort), key=types_sort.count)\n",
    "        predictions.append(maxx)\n",
    "    y_test = y_test.tolist()\n",
    "    all_predicts.extend(predictions)\n",
    "    tests.extend(y_test)\n",
    "    \n",
    "print(classification_report(tests, all_predicts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
