{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format(\"D:/wiki.de.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decapitalize(word):\n",
    "    if len(word) > 1:\n",
    "        word = word[0].lower() + word[1:]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#distance between compound parts: not normalized\n",
    "def dist_not_norm(a,b):\n",
    "    a_rev=a[::-1]\n",
    "    b_rev=b[::-1]\n",
    "    count = 0\n",
    "    for i in range(min(len(a), len(b))):\n",
    "        if a_rev[i] != b_rev[i]:\n",
    "            break\n",
    "        else:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#distance between compound parts: normalized\n",
    "def dist_norm(a,b):\n",
    "    return 1-(dist_not_norm(a,b)/((len(a)+len(b))/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no suffixes\n",
    "def all_dist(vector_1,vector_2):\n",
    "    cur_dist = 0\n",
    "    for i in range((len(vector_1))):\n",
    "        if i == 0 or i == 2:\n",
    "            ith_dist = dist_norm(vector_1[i], vector_2[i])\n",
    "            cur_dist += ith_dist * ith_dist\n",
    "            try:\n",
    "                ith_dist = glove_model.similarity(decapitalize(vector_1[i]), decapitalize(vector_2[i]))\n",
    "                cur_dist += (1-ith_dist)*(1-ith_dist)\n",
    "            except:\n",
    "                ith_dist = 0\n",
    "                cur_dist += (1-ith_dist)*(1-ith_dist)\n",
    "        else:\n",
    "            if vector_1[i] != vector_2[i]:\n",
    "                cur_dist += 1\n",
    "    return cur_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"C:/Users/1/Desktop/compounds_final.txt\", \"r\", encoding=\"utf-8\")\n",
    "lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no suffixes\n",
    "matrix = []\n",
    "for line in lines:\n",
    "    vectors = []\n",
    "    types = []\n",
    "    line = line.strip(\"\\n\")\n",
    "    items = line.split(\"/\")\n",
    "    items_new = items[1:3] + items[4:6] + [items[7]]\n",
    "    for item in items_new:\n",
    "        vectors.append(item)\n",
    "    types.append(items[-1])\n",
    "    tp = (vectors,types)\n",
    "    matrix.append(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Engel', '<NN>', 'Bild', '<+NN>', 's'], ['N'])\n",
      "(['Wolke', '<NN>', 'Schatten', '<+NN>', 'n'], ['NN'])\n"
     ]
    }
   ],
   "source": [
    "for item in matrix[:2]:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixX = []\n",
    "matrixY = []\n",
    "for item in matrix:\n",
    "    matrixX.append(item[0])\n",
    "    matrixY.append(item[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(matrixX)\n",
    "y = np.array(matrixY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         AN       0.48      0.45      0.46      1349\n",
      "          N       0.42      0.54      0.47      1250\n",
      "         NN       0.24      0.11      0.15       540\n",
      "\n",
      "avg / total       0.41      0.43      0.41      3139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_predicts = []\n",
    "tests = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    predictions = []\n",
    "    for vector in X_test:\n",
    "        distances = []\n",
    "        types = []\n",
    "        for x in range(len(X_train)):\n",
    "            distance = all_dist(X_train[x], vector)\n",
    "            d_t = (distance, y_train[x])\n",
    "            distances.append(d_t)\n",
    "            types.append(y_train[x])\n",
    "        distances_sort = sorted(distances)\n",
    "        types_sort = []\n",
    "        for item in distances_sort[:3]:\n",
    "            types_sort.append(item[1])\n",
    "        maxx = max(set(types_sort), key=types_sort.count)\n",
    "        predictions.append(maxx)\n",
    "    y_test = y_test.tolist()\n",
    "    all_predicts.extend(predictions)\n",
    "    tests.extend(y_test)\n",
    "    \n",
    "print(classification_report(tests, all_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with suffixes\n",
    "def all_dist(vector_1,vector_2):\n",
    "    cur_dist = 0\n",
    "    for i in range((len(vector_1))):\n",
    "        if i == 0 or i == 3:\n",
    "            ith_dist = dist_norm(vector_1[i], vector_2[i])\n",
    "            cur_dist += ith_dist * ith_dist\n",
    "            try:\n",
    "                ith_dist = glove_model.similarity(decapitalize(vector_1[i]), decapitalize(vector_2[i]))\n",
    "                cur_dist += (1-ith_dist)*(1-ith_dist)\n",
    "            except:\n",
    "                ith_dist = 0\n",
    "                cur_dist += (1-ith_dist)*(1-ith_dist)\n",
    "        else:\n",
    "            if vector_1[i] != vector_2[i]:\n",
    "                cur_dist += 1\n",
    "    return cur_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with suffixes\n",
    "matrix = []\n",
    "for line in lines:\n",
    "    vectors = []\n",
    "    types = []\n",
    "    line = line.strip(\"\\n\")\n",
    "    items = line.split(\"/\")\n",
    "    items_new = items[1:8]\n",
    "    for item in items_new:\n",
    "        vectors.append(item)\n",
    "    types.append(items[-1])\n",
    "    tp = (vectors,types)\n",
    "    matrix.append(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Engel', '<NN>', 'no', 'Bild', '<+NN>', 'no', 's'], ['N'])\n",
      "(['Wolke', '<NN>', 'no', 'Schatten', '<+NN>', 'no', 'n'], ['NN'])\n"
     ]
    }
   ],
   "source": [
    "for item in matrix[:2]:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixX = []\n",
    "matrixY = []\n",
    "for item in matrix:\n",
    "    matrixX.append(item[0])\n",
    "    matrixY.append(item[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(matrixX)\n",
    "y = np.array(matrixY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         AN       0.47      0.44      0.46      1349\n",
      "          N       0.42      0.55      0.48      1250\n",
      "         NN       0.26      0.11      0.15       540\n",
      "\n",
      "avg / total       0.42      0.43      0.41      3139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_predicts = []\n",
    "tests = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    predictions = []\n",
    "    for vector in X_test:\n",
    "        distances = []\n",
    "        types = []\n",
    "        for x in range(len(X_train)):\n",
    "            distance = all_dist(X_train[x], vector)\n",
    "            d_t = (distance, y_train[x])\n",
    "            distances.append(d_t)\n",
    "            types.append(y_train[x])\n",
    "        distances_sort = sorted(distances)\n",
    "        types_sort = []\n",
    "        for item in distances_sort[:3]:\n",
    "            types_sort.append(item[1])\n",
    "        maxx = max(set(types_sort), key=types_sort.count)\n",
    "        predictions.append(maxx)\n",
    "    y_test = y_test.tolist()\n",
    "    all_predicts.extend(predictions)\n",
    "    tests.extend(y_test)\n",
    "    \n",
    "print(classification_report(tests, all_predicts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
